{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VCS_create_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3DkdaGNJV5oW",
        "_Gm9cB43WFET",
        "AWY-MEk4YAKY",
        "ojT358srLyLE",
        "k3m2HdWPTqWh",
        "du2u3Zz0ka1i",
        "buM9o--4kfY1"
      ],
      "mount_file_id": "1-wi11vpJMThrQ5jA5qnjpQGOEwDykElN",
      "authorship_tag": "ABX9TyMYatQkOunbJGZdREI00ja/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PozzaMarco/VCS_Pix2Pix_Implementation/blob/main/VCS_create_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook provide all the functionalities to create a proper masked dataset for the pix2pix GAN.\n"
      ],
      "metadata": {
        "id": "vW-Gqx0wUPle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "NeHB3lF-VAPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "x7AuPVBYc6E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WJWT3bsULSH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import image as image_loader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "from PIL import Image, ImageOps"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seed\n",
        "Setting seeds for reproducibility."
      ],
      "metadata": {
        "id": "3DkdaGNJV5oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "keras.utils.set_random_seed(SEED)"
      ],
      "metadata": {
        "id": "QS5-CLUQVvwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "Utility function used in the whole project."
      ],
      "metadata": {
        "id": "Afz_qSXZV8tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_dataset(folder_num = 0):\n",
        "  import shutil\n",
        "\n",
        "  if folder_num == 1:\n",
        "    shutil.rmtree('/content/dataset')\n",
        "  elif folder_num == 2:\n",
        "    shutil.rmtree('/content/joint_dataset')\n",
        "  else:\n",
        "    print(f\"1: Dataset \\n 2: Joint_dataset\")\n",
        "\n",
        "def extract_label(encoded_label):\n",
        "  label = str(encoded_label.numpy())\n",
        "  label = label.replace(\"'\",\"\")\n",
        "  label = label[1:]\n",
        "  return label\n",
        "\n",
        "def create_dataset_folders(path):\n",
        "  if(os.path.isdir(path) == False):\n",
        "    os.makedirs(path)\n",
        "    os.mkdir(path+\"/train\")\n",
        "    os.mkdir(path+\"/val\")\n",
        "  \n",
        "  else:\n",
        "    if(os.path.isdir(path+\"/train\") == False):\n",
        "      os.mkdir(path+\"/train\")\n",
        "    if(os.path.isdir(path+\"/val\") == False):\n",
        "      os.mkdir(path+\"/val\")\n",
        "\n",
        "def get_patches(image, image_dim, patch_size, mask_proprotions):\n",
        "  num_patches = (image_dim // patch_size) ** 2\n",
        "\n",
        "  resized_image = cv2.resize(image, dsize=(image_dim, image_dim), interpolation=cv2.INTER_CUBIC)\n",
        "  batch_resized_image = np.expand_dims(resized_image, axis=0)\n",
        "\n",
        "  patch_layer = Patches(patch_size=patch_size)\n",
        "  patches = patch_layer(images=batch_resized_image)\n",
        "\n",
        "  return patches, resized_image, patch_layer\n",
        "\n",
        "def crop_resize_image(image, size):\n",
        "  size = (size, size)\n",
        "  new_image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "  return new_image\n",
        "\n",
        "def create_masked_image(image, patch_size, mask_extension):\n",
        "  image_dim = 250\n",
        "  projection_dim = 128\n",
        "\n",
        "  patches, resized_image, patch_layer = get_patches(image,image_dim, patch_size, mask_extension)\n",
        "  patch_encoder = PatchEncoder(patch_size, projection_dim, mask_extension)\n",
        "  (\n",
        "      unmasked_embeddings,\n",
        "      masked_embeddings,\n",
        "      unmasked_positions,\n",
        "      mask_indices,\n",
        "      unmask_indices,\n",
        "  ) = patch_encoder(patches=patches)\n",
        "\n",
        "  new_patch, random_index = patch_encoder.generate_masked_image(patches, unmask_indices)\n",
        "  masked_img = patch_layer.reconstruct_from_patch(new_patch).numpy()\n",
        "\n",
        "  if(masked_img.shape != (250, 250, 3)):\n",
        "    masked_img = pad_img(masked_img)\n",
        "\n",
        "  masked_image = cv2.cvtColor(masked_img, cv2.COLOR_BGR2RGB)\n",
        "  return masked_image, resized_image\n",
        "\n",
        "def pad_img(input_image):\n",
        "  old_image_height, old_image_width, channels = input_image.shape\n",
        "\n",
        "  # create new image of desired size and color (black) for padding\n",
        "  new_image_width = 250\n",
        "  new_image_height = 250\n",
        "  color = (255,255,255)\n",
        "  result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
        "\n",
        "  # compute center offset\n",
        "  x_center = (new_image_width - old_image_width) // 2\n",
        "  y_center = (new_image_height - old_image_height) // 2\n",
        "\n",
        "  # copy img image into center of result image\n",
        "  result[y_center:y_center+old_image_height, \n",
        "        x_center:x_center+old_image_width] = input_image\n",
        "  \n",
        "  return result\n",
        "\n",
        "def save_images(image, masked_image, filename):\n",
        "  cv2.imwrite(filename, image)\n",
        "  cv2.imwrite(filename+\"_masked.jpg\", cv2.cvtColor(masked_image, cv2.COLOR_RGB2BGR))\n",
        "  pass\n",
        "\n",
        "def create_masked_dataset(path, save_path, patch_size, mask_extension, test = False):\n",
        "  new_size = 200\n",
        "  list_files = sorted(os.listdir(path))\n",
        "  num_images = len(list_files)\n",
        "  create_dataset_folders(save_path)\n",
        "  extension = path.split(\"/\")[8]\n",
        "  print(f\"Processing {extension} images\")\n",
        "\n",
        "  if (test == True):\n",
        "    num_images = 5\n",
        "    \n",
        "  for idx in tqdm_notebook(range(num_images)):\n",
        "    img_name = list_files[idx]\n",
        "    img_path = os.path.join(path, img_name)\n",
        "    image = Image.open(img_path)\n",
        "\n",
        "    preprocessed_image = crop_resize_image(image, new_size)\n",
        "    image = cv2.cvtColor(np.array(preprocessed_image), cv2.COLOR_BGR2RGB)\n",
        "    masked_image, resized_image = create_masked_image(image, patch_size, mask_extension)\n",
        "\n",
        "    label =  img_name\n",
        "    \n",
        "    filename = save_path+\"/\"+extension+\"/\"+label    \n",
        "    save_images(resized_image, masked_image, filename)\n",
        "    \n",
        "def join_images(path_to_dir):\n",
        "  list_files = sorted(os.listdir(path_to_dir))\n",
        "\n",
        "  extension = path_to_dir.split(\"/\")[4]\n",
        "  save_path = \"/content/joint_dataset/data/\"\n",
        "  create_dataset_folders(save_path)\n",
        "\n",
        "  save_path += extension+\"/\"\n",
        "  print(save_path)\n",
        "  \n",
        "  for idx in tqdm_notebook(range(len(list_files))):\n",
        "    if(idx % 2 == 0):\n",
        "      img_file = list_files[idx]\n",
        "      img_path = os.path.join(path_to_dir, img_file)\n",
        "      image = np.array(Image.open(img_path))\n",
        "\n",
        "      masked_img_file = list_files[idx + 1]\n",
        "      masked_img_path = os.path.join(path_to_dir, masked_img_file)\n",
        "      masked_image = np.array(Image.open(masked_img_path))\n",
        "\n",
        "      full =  np.concatenate((image, masked_image), axis = 1)\n",
        "\n",
        "      cv2.imwrite(save_path+img_file, cv2.cvtColor(full, cv2.COLOR_RGB2BGR))"
      ],
      "metadata": {
        "id": "P304qwdAV_Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes\n",
        "Implementation of the classes for creating the PatchEncoder that allow to create the masked patches with different sizes and extensions."
      ],
      "metadata": {
        "id": "_Gm9cB43WFET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        # Assuming the image has three channels each patch would be\n",
        "        # of size (patch_size, patch_size, 3).\n",
        "        self.resize = layers.Reshape((-1, patch_size * patch_size * 3))\n",
        "\n",
        "    def call(self, images):\n",
        "        # Create patches from the input images\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "\n",
        "        # Reshape the patches to (batch, num_patches, patch_area) and return it.\n",
        "        patches = self.resize(patches)\n",
        "        return patches\n",
        "\n",
        "    def show_patched_image(self, images, patches):\n",
        "        # This is a utility function which accepts a batch of images and its\n",
        "        # corresponding patches and help visualize one image and its patches\n",
        "        # side by side.\n",
        "        idx = np.random.choice(patches.shape[0])\n",
        "        print(f\"Index selected: {idx}.\")\n",
        "\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.imshow(keras.utils.array_to_img(images[idx]))\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        n = int(np.sqrt(patches.shape[1]))\n",
        "\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        for i, patch in enumerate(patches[idx]):\n",
        "            ax = plt.subplot(n, n, i + 1)\n",
        "            patch_img = tf.reshape(patch, (self.patch_size, self.patch_size, 3))\n",
        "            plt.imshow((keras.utils.img_to_array(patch_img)).astype(np.uint8))\n",
        "            plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        # Return the index chosen to validate it outside the method.\n",
        "        return idx\n",
        "\n",
        "    # taken from https://stackoverflow.com/a/58082878/10319735\n",
        "    def reconstruct_from_patch(self, patch):\n",
        "        # This utility function takes patches from a *single* image and\n",
        "        # reconstructs it back into the image. This is useful for the train\n",
        "        # monitor callback.\n",
        "        num_patches = patch.shape[0]\n",
        "        n = int(np.sqrt(num_patches))\n",
        "        patch = tf.reshape(patch, (num_patches, self.patch_size, self.patch_size, 3))\n",
        "        rows = tf.split(patch, n, axis=0)\n",
        "        rows = [tf.concat(tf.unstack(x), axis=1) for x in rows]\n",
        "        reconstructed = tf.concat(rows, axis=0)\n",
        "        return reconstructed\n",
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        patch_size,\n",
        "        projection_dim,\n",
        "        mask_proportion,\n",
        "        downstream=False,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.patch_size = patch_size\n",
        "        self.projection_dim = projection_dim\n",
        "        self.mask_proportion = mask_proportion\n",
        "        self.downstream = downstream\n",
        "\n",
        "        # This is a trainable mask token initialized randomly from a normal\n",
        "        # distribution.\n",
        "        self.mask_token = tf.Variable(\n",
        "            tf.random.normal([1, patch_size * patch_size * 3]), trainable=True\n",
        "        )\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        (_, self.num_patches, self.patch_area) = input_shape\n",
        "\n",
        "        # Create the projection layer for the patches.\n",
        "        self.projection = layers.Dense(units=self.projection_dim)\n",
        "\n",
        "        # Create the positional embedding layer.\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=self.num_patches, output_dim=self.projection_dim\n",
        "        )\n",
        "\n",
        "        # Number of patches that will be masked.\n",
        "        self.num_mask = int(self.mask_proportion * self.num_patches)\n",
        "\n",
        "    def call(self, patches):\n",
        "        # Get the positional embeddings.\n",
        "        batch_size = tf.shape(patches)[0]\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        pos_embeddings = self.position_embedding(positions[tf.newaxis, ...])\n",
        "        pos_embeddings = tf.tile(\n",
        "            pos_embeddings, [batch_size, 1, 1]\n",
        "        )  # (B, num_patches, projection_dim)\n",
        "\n",
        "        # Embed the patches.\n",
        "        patch_embeddings = (\n",
        "            self.projection(patches) + pos_embeddings\n",
        "        )  # (B, num_patches, projection_dim)\n",
        "\n",
        "        if self.downstream:\n",
        "            return patch_embeddings\n",
        "        else:\n",
        "            mask_indices, unmask_indices = self.get_random_indices(batch_size)\n",
        "            # The encoder input is the unmasked patch embeddings. Here we gather\n",
        "            # all the patches that should be unmasked.\n",
        "            unmasked_embeddings = tf.gather(\n",
        "                patch_embeddings, unmask_indices, axis=1, batch_dims=1\n",
        "            )  # (B, unmask_numbers, projection_dim)\n",
        "\n",
        "            # Get the unmasked and masked position embeddings. We will need them\n",
        "            # for the decoder.\n",
        "            unmasked_positions = tf.gather(\n",
        "                pos_embeddings, unmask_indices, axis=1, batch_dims=1\n",
        "            )  # (B, unmask_numbers, projection_dim)\n",
        "            masked_positions = tf.gather(\n",
        "                pos_embeddings, mask_indices, axis=1, batch_dims=1\n",
        "            )  # (B, mask_numbers, projection_dim)\n",
        "\n",
        "            # Repeat the mask token number of mask times.\n",
        "            # Mask tokens replace the masks of the image.\n",
        "            mask_tokens = tf.repeat(self.mask_token, repeats=self.num_mask, axis=0)\n",
        "            mask_tokens = tf.repeat(\n",
        "                mask_tokens[tf.newaxis, ...], repeats=batch_size, axis=0\n",
        "            )\n",
        "\n",
        "            # Get the masked embeddings for the tokens.\n",
        "            masked_embeddings = self.projection(mask_tokens) + masked_positions\n",
        "            return (\n",
        "                unmasked_embeddings,  # Input to the encoder.\n",
        "                masked_embeddings,  # First part of input to the decoder.\n",
        "                unmasked_positions,  # Added to the encoder outputs.\n",
        "                mask_indices,  # The indices that were masked.\n",
        "                unmask_indices,  # The indices that were unmaksed.\n",
        "            )\n",
        "\n",
        "    def get_random_indices(self, batch_size):\n",
        "        # Create random indices from a uniform distribution and then split\n",
        "        # it into mask and unmask indices.\n",
        "        rand_indices = tf.argsort(\n",
        "            tf.random.uniform(shape=(batch_size, self.num_patches)), axis=-1\n",
        "        )\n",
        "        mask_indices = rand_indices[:, : self.num_mask]\n",
        "        unmask_indices = rand_indices[:, self.num_mask :]\n",
        "        return mask_indices, unmask_indices\n",
        "\n",
        "    def generate_masked_image(self, patches, unmask_indices):\n",
        "        # Choose a random patch and it corresponding unmask index.\n",
        "        idx = np.random.choice(patches.shape[0])\n",
        "        patch = patches[idx]\n",
        "        unmask_index = unmask_indices[idx]\n",
        "\n",
        "        # Build a numpy array of same shape as patch.\n",
        "        new_patch = np.zeros_like(patch)\n",
        "\n",
        "        # Iterate of the new_patch and plug the unmasked patches.\n",
        "        count = 0\n",
        "        for i in range(unmask_index.shape[0]):\n",
        "            new_patch[unmask_index[i]] = patch[unmask_index[i]]\n",
        "        return new_patch, idx\n"
      ],
      "metadata": {
        "id": "MTSSVEA1WKxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create masked images\n",
        "Procedure that loads the training/validation sets and uses two hyperparameters to set the patch size and the extension.\n",
        "The variable \"test\" is used to create 5 images to see if the patch sizes and the extensions is as wanted."
      ],
      "metadata": {
        "id": "AWY-MEk4YAKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tpath_train = \"/content/drive/MyDrive/VCS_datasets/extended_dataset/cub200/data/train\"\n",
        "path_val = \"/content/drive/MyDrive/VCS_datasets/extended_dataset/cub200/data/val\"\n",
        "save_path = \"/content/dataset/data\"\n",
        "\n",
        "patch_size = 35\n",
        "mask_extension = 0.15\n",
        "test = False\n",
        "\n",
        "create_masked_dataset(path_train, save_path, patch_size, mask_extension, test)\n",
        "create_masked_dataset(path_val, save_path, patch_size, mask_extension, test)"
      ],
      "metadata": {
        "id": "ynnkwRWMZ09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compact images\n",
        "For each pair of images (patched - original) I create a new image that is doubled in length in order to have the patched image and the original image one after the other.\n",
        "So from two images I create just one with the two images adjacent."
      ],
      "metadata": {
        "id": "ojT358srLyLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_masked_train = \"/content/dataset/data/train\"\n",
        "path_masked_val = \"/content/dataset/data/val\"\n",
        "\n",
        "join_images(path_masked_train)\n",
        "join_images(path_masked_val)"
      ],
      "metadata": {
        "id": "npFHXBv4Lx4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Zip for save\n",
        "Make a zip file of the newly created images for a easy download."
      ],
      "metadata": {
        "id": "k3m2HdWPTqWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Make dataset to zip to download it\n",
        "!zip -r /content/caltech_birds_masked_35_15_joint.zip /content/joint_dataset/"
      ],
      "metadata": {
        "id": "WOn0p_kVTtl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Delete datasets\n",
        "After having downloaded the images,  reset the workspace by deleting the folder containing the datasets.\n",
        "This is done for a fresh restart of the whole process of masked image generation."
      ],
      "metadata": {
        "id": "S0i4Hk0HX3AX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Delete dataset"
      ],
      "metadata": {
        "id": "du2u3Zz0ka1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_dataset(1)"
      ],
      "metadata": {
        "id": "PBgI0cluX5G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete joint dataset"
      ],
      "metadata": {
        "id": "buM9o--4kfY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_dataset(2)"
      ],
      "metadata": {
        "id": "iz4Genz5kjFS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}